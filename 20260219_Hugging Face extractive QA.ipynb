{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a24208d-0b60-4226-8ff2-aec1b5eb854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.10.0-cp313-cp313-win_amd64.whl.metadata (31 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Downloading typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\katie\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.10.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\katie\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\katie\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\katie\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katie\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\katie\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\katie\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Collecting langchain-core<2.0.0,>=1.2.10 (from langchain)\n",
      "  Downloading langchain_core-1.2.13-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.8 (from langchain)\n",
      "  Downloading langgraph-1.0.8-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
      "  Downloading langsmith-0.7.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (9.1.2)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
      "  Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading langgraph_sdk-0.3.6-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading ormsgpack-1.12.2-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
      "  Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\katie\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting typer>=0.24.0 (from typer-slim->transformers)\n",
      "  Downloading typer-0.24.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.2.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers) (8.2.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers) (14.2.0)\n",
      "Collecting annotated-doc>=0.0.2 (from typer>=0.24.0->typer-slim->transformers)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\katie\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
      "Downloading transformers-5.2.0-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 1.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/10.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.4/10.4 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.5/10.4 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.6/10.4 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.1/10.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 4.0 MB/s  0:00:02\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 553.3/553.3 kB 9.7 MB/s  0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.6/2.9 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 8.4 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.8/2.7 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 9.5 MB/s  0:00:00\n",
      "Downloading torch-2.10.0-cp313-cp313-win_amd64.whl (113.8 MB)\n",
      "   ---------------------------------------- 0.0/113.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.4/113.8 MB 12.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 5.2/113.8 MB 12.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 8.4/113.8 MB 13.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 10.7/113.8 MB 13.3 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 13.1/113.8 MB 12.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 15.5/113.8 MB 12.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 18.6/113.8 MB 12.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 21.5/113.8 MB 13.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 25.2/113.8 MB 13.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 29.4/113.8 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 34.3/113.8 MB 15.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 37.7/113.8 MB 15.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 43.0/113.8 MB 15.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 47.2/113.8 MB 16.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 52.4/113.8 MB 16.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 58.5/113.8 MB 17.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 62.4/113.8 MB 17.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 66.3/113.8 MB 17.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 70.8/113.8 MB 17.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 74.4/113.8 MB 17.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 78.4/113.8 MB 17.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 81.5/113.8 MB 17.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 85.2/113.8 MB 17.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 89.4/113.8 MB 17.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 94.4/113.8 MB 18.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 98.8/113.8 MB 18.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 103.5/113.8 MB 18.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 109.1/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.8/113.8 MB 13.7 MB/s  0:00:08\n",
      "Downloading langchain-1.2.10-py3-none-any.whl (111 kB)\n",
      "Downloading langchain_core-1.2.13-py3-none-any.whl (500 kB)\n",
      "Downloading langgraph-1.0.8-py3-none-any.whl (158 kB)\n",
      "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.6-py3-none-any.whl (88 kB)\n",
      "Downloading langsmith-0.7.4-py3-none-any.whl (325 kB)\n",
      "Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 9.3 MB/s  0:00:00\n",
      "Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl (124 kB)\n",
      "Downloading ormsgpack-1.12.2-cp313-cp313-win_amd64.whl (117 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Downloading typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\n",
      "Downloading typer-0.24.0-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: xxhash, uuid-utils, sentencepiece, safetensors, ormsgpack, orjson, hf-xet, annotated-doc, torch, typer, langsmith, langgraph-sdk, typer-slim, langchain-core, langgraph-checkpoint, huggingface-hub, tokenizers, langgraph-prebuilt, transformers, langgraph, langchain\n",
      "\n",
      "   ----- ----------------------------------  3/21 [safetensors]\n",
      "   ------------- --------------------------  7/21 [annotated-doc]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "  Attempting uninstall: typer\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "    Found existing installation: typer 0.17.4\n",
      "   --------------- ------------------------  8/21 [torch]\n",
      "   ----------------- ----------------------  9/21 [typer]\n",
      "    Uninstalling typer-0.17.4:\n",
      "   ----------------- ----------------------  9/21 [typer]\n",
      "      Successfully uninstalled typer-0.17.4\n",
      "   ----------------- ----------------------  9/21 [typer]\n",
      "   ----------------- ----------------------  9/21 [typer]\n",
      "   ----------------- ----------------------  9/21 [typer]\n",
      "   ------------------- -------------------- 10/21 [langsmith]\n",
      "   ------------------- -------------------- 10/21 [langsmith]\n",
      "   ------------------- -------------------- 10/21 [langsmith]\n",
      "   ------------------- -------------------- 10/21 [langsmith]\n",
      "   -------------------- ------------------- 11/21 [langgraph-sdk]\n",
      "   ------------------------ --------------- 13/21 [langchain-core]\n",
      "   ------------------------ --------------- 13/21 [langchain-core]\n",
      "   ------------------------ --------------- 13/21 [langchain-core]\n",
      "   ------------------------ --------------- 13/21 [langchain-core]\n",
      "   ------------------------ --------------- 13/21 [langchain-core]\n",
      "   -------------------------- ------------- 14/21 [langgraph-checkpoint]\n",
      "   ---------------------------- ----------- 15/21 [huggingface-hub]\n",
      "   ---------------------------- ----------- 15/21 [huggingface-hub]\n",
      "   ---------------------------- ----------- 15/21 [huggingface-hub]\n",
      "   ---------------------------- ----------- 15/21 [huggingface-hub]\n",
      "   ---------------------------- ----------- 15/21 [huggingface-hub]\n",
      "   ------------------------------ --------- 16/21 [tokenizers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ---------------------------------- ----- 18/21 [transformers]\n",
      "   ------------------------------------ --- 19/21 [langgraph]\n",
      "   ------------------------------------ --- 19/21 [langgraph]\n",
      "   -------------------------------------- - 20/21 [langchain]\n",
      "   ---------------------------------------- 21/21 [langchain]\n",
      "\n",
      "Successfully installed annotated-doc-0.0.4 hf-xet-1.2.0 huggingface-hub-1.4.1 langchain-1.2.10 langchain-core-1.2.13 langgraph-1.0.8 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.6 langsmith-0.7.4 orjson-3.11.7 ormsgpack-1.12.2 safetensors-0.7.0 sentencepiece-0.2.1 tokenizers-0.22.2 torch-2.10.0 transformers-5.2.0 typer-0.24.0 typer-slim-0.24.0 uuid-utils-0.14.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch langchain sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad7c90a-4ed4-4cfb-a8c5-81ddb6c608d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仿單長度: 5700 字\n",
      "安美達錠1毫克\n",
      "# Arimidex Tablets 1mg\n",
      "\n",
      "| 非常常見         | 心血管：         | • 熱潮紅，通常為輕至中度      |\n",
      "| ------------ | ------------ | ------------------ |\n",
      "| 一般：          | • 無力，通常為輕至中度 | 肌肉骨骼和結締組織方面的異常：    |\n",
      "| • 關節痛/關\n"
     ]
    }
   ],
   "source": [
    "with open(\"arimidex_full_parsed.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    context = f.read()\n",
    "\n",
    "print(f\"仿單長度: {len(context)} 字\")\n",
    "print(context[:200]) # 檢查一下內容對不對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c62032e-29c0-40fd-967d-6c8ab669a516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b51c6b448d9405eb4c91f59d826f97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForQuestionAnswering LOAD REPORT\u001b[0m from: uer/roberta-base-chinese-extractive-qa\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型載入完成！\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 載入一個已經會做中文問答的模型\n",
    "# 這裡選用一個專精中文 extractive QA 的模型\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"uer/roberta-base-chinese-extractive-qa\",\n",
    "    tokenizer=\"uer/roberta-base-chinese-extractive-qa\"\n",
    ")\n",
    "\n",
    "print(\"模型載入完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00565b2c-1b76-4753-9c58-57f74b4e6960",
   "metadata": {},
   "source": [
    "## 改良的切分策略：依 Markdown 段落切塊\n",
    "\n",
    "Extractive QA 的限制是：模型一次只能讀約 512 個字。直接把整份仿單丟進去會報錯。\n",
    "\n",
    "**原本**的做法是每 400 字切一塊（固定長度），**缺點**是可能把一個完整段落切到兩半——例如「禁忌」的清單只有 200 字，卻和前一段的末尾拼在一起；「不良反應」的段落超過 400 字，被攔腰切斷後模型只看到一半的資訊。\n",
    "\n",
    "**改良後**的做法：依 Markdown 的標題（`#`）來切段，讓每個片段剛好對應一個主題。同時把標題加在片段前面，讓模型知道這段文字的主題。\n",
    "\n",
    "切出來的片段會長這樣：\n",
    "```\n",
    "【禁忌】\n",
    "'Arimidex'禁用於：\n",
    "- 停經前婦女\n",
    "- 懷孕或授乳婦\n",
    "...\n",
    "\n",
    "【用法用量】\n",
    "1. 成人(包括老人)：口服一天一錠 (1mg)。\n",
    "...\n",
    "\n",
    "【非預期的作用】\n",
    "使用'Arimidex'之病患有較少之熱潮紅、陰道出血...\n",
    "```\n",
    "\n",
    "（備註：這就是為什麼 RAG 比較強，因為 RAG 還會再加上語意搜尋，Extractive QA 需要自己寫這些邏輯）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994ff77b-242f-4ef6-9692-3c8159dc53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共切成 28 個片段：\n",
      "  片段  0: 【藥品基本資訊】（16 字）\n",
      "  片段  1: 【Arimidex Tablets 1mg】（450 字）\n",
      "  片段  2: 【Arimidex Tablets 1mg】（46 字）\n",
      "  片段  3: 【Anastrozole 膜衣錠】（81 字）\n",
      "  片段  4: 【適應症】（139 字）\n",
      "  片段  5: 【用法用量】（162 字）\n",
      "  片段  6: 【禁忌】（194 字）\n",
      "  片段  7: 【交互作用】（330 字）\n",
      "  片段  8: 【過量】（271 字）\n",
      "  片段  9: 【藥效動力學特性】（431 字）\n",
      "  片段 10: 【妊娠與授乳】（29 字）\n",
      "  片段 11: 【對開車或其他使用機械能力的影響】（97 字）\n",
      "  片段 12: 【非預期的作用】（403 字）\n",
      "  片段 13: 【活率之益處方面】（450 字）\n",
      "  片段 14: 【活率之益處方面】（199 字）\n",
      "  片段 15: 【輔助治療已使用過tamoxifen之早期乳癌】（250 字）\n",
      "  片段 16: 【急性毒性】（130 字）\n",
      "  片段 17: 【慢性毒性】（156 字）\n",
      "  片段 18: 【突變性】（58 字）\n",
      "  片段 19: 【生殖毒性】（208 字）\n",
      "  片段 20: 【致癌性】（177 字）\n",
      "  片段 21: 【脂質】（79 字）\n",
      "  片段 22: 【兒童】（75 字）\n",
      "  片段 23: 【男性女乳症臨床研究】（326 字）\n",
      "  片段 24: 【馬科恩‑亞白特氏症候群(McCune Albright Syndrome, MAS)臨床研究】（352 字）\n",
      "  片段 25: 【整體評估】（32 字）\n",
      "  片段 26: 【藥物動力學特性】（250 字）\n",
      "  片段 27: 【製造廠】（242 字）\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 改良切分策略：依 Markdown 標題切段，保留標題作為 context 前綴\n",
    "# 優點：同一段落的資訊不會被切斷，「禁忌」、「用法用量」等各自獨立成塊\n",
    "def chunk_by_sections(text, max_length=450):\n",
    "    sections = []\n",
    "    current_title = \"藥品基本資訊\"\n",
    "    current_lines = []\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        if re.match(r'^#{1,3} ', line):\n",
    "            # 儲存前一段\n",
    "            content = '\\n'.join(current_lines).strip()\n",
    "            if content:\n",
    "                prefix = f\"【{current_title}】\\n\"\n",
    "                full = prefix + content\n",
    "                if len(full) <= max_length:\n",
    "                    sections.append(full)\n",
    "                else:\n",
    "                    # 太長就再切，但每個子片段都保留標題前綴\n",
    "                    step = max_length - len(prefix)\n",
    "                    for i in range(0, len(content), step):\n",
    "                        sections.append(prefix + content[i:i + step])\n",
    "            current_title = re.sub(r'^#+\\s*', '', line).rstrip('：').strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            current_lines.append(line)\n",
    "\n",
    "    # 最後一段\n",
    "    content = '\\n'.join(current_lines).strip()\n",
    "    if content:\n",
    "        prefix = f\"【{current_title}】\\n\"\n",
    "        full = prefix + content\n",
    "        if len(full) <= max_length:\n",
    "            sections.append(full)\n",
    "        else:\n",
    "            step = max_length - len(prefix)\n",
    "            for i in range(0, len(content), step):\n",
    "                sections.append(prefix + content[i:i + step])\n",
    "\n",
    "    return sections\n",
    "\n",
    "chunks = chunk_by_sections(context)\n",
    "print(f\"總共切成 {len(chunks)} 個片段：\")\n",
    "for i, c in enumerate(chunks):\n",
    "    first_line = c.split('\\n')[0]\n",
    "    print(f\"  片段 {i:2d}: {first_line}（{len(c)} 字）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826415dd-fbac-4513-a9af-bb5a59ac0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義問答函數（同時回傳答案來源的段落，方便 debug）\n",
    "def ask_arimidex(question):\n",
    "    best_answer = {\"score\": 0, \"answer\": \"找不到答案\", \"section\": \"\"}\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            result = qa_pipeline(question=question, context=chunk)\n",
    "            if result['score'] > best_answer['score']:\n",
    "                best_answer = result\n",
    "                best_answer['chunk_id'] = i\n",
    "                best_answer['section'] = chunk.split('\\n')[0]  # 記錄答案來自哪個段落\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return best_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a21aa5-812a-452a-bc0d-07055335e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題: 這藥的適應症是什麼？\n",
      "答案: 治療停經後婦女晚期乳癌\n",
      "來源段落: 【適應症】\n",
      "信心分數: 0.4547\n"
     ]
    }
   ],
   "source": [
    "question = \"這藥的適應症是什麼？\"\n",
    "result = ask_arimidex(question)\n",
    "\n",
    "print(f\"問題: {question}\")\n",
    "print(f\"答案: {result['answer']}\")\n",
    "print(f\"來源段落: {result.get('section', '未知')}\")\n",
    "print(f\"信心分數: {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca721670-f902-49f9-9353-3e5fbce2c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題: 不良反應包含哪些？\n",
      "答案: 關節炎、關節退化及關節痛\n",
      "來源段落: 【活率之益處方面】\n",
      "信心分數: 0.0084\n"
     ]
    }
   ],
   "source": [
    "question = \"不良反應包含哪些？\"\n",
    "result = ask_arimidex(question)\n",
    "\n",
    "print(f\"問題: {question}\")\n",
    "print(f\"答案: {result['answer']}\")\n",
    "print(f\"來源段落: {result.get('section', '未知')}\")\n",
    "print(f\"信心分數: {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3de3672-d5c9-4b1e-98c4-b8f05a0238c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題: 什麼人不能吃？\n",
      "答案: 狗\n",
      "來源段落: 【急性毒性】\n",
      "信心分數: 0.0006\n"
     ]
    }
   ],
   "source": [
    "question = \"什麼人不能吃？\"\n",
    "result = ask_arimidex(question)\n",
    "\n",
    "print(f\"問題: {question}\")\n",
    "print(f\"答案: {result['answer']}\")\n",
    "print(f\"來源段落: {result.get('section', '未知')}\")\n",
    "print(f\"信心分數: {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89550302-78a2-4432-82b9-72a0a9b96dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題: 怎麼服用？\n",
      "答案: 口服\n",
      "來源段落: 【用法用量】\n",
      "信心分數: 0.0964\n"
     ]
    }
   ],
   "source": [
    "question = \"怎麼服用？\"\n",
    "result = ask_arimidex(question)\n",
    "\n",
    "print(f\"問題: {question}\")\n",
    "print(f\"答案: {result['answer']}\")\n",
    "print(f\"來源段落: {result.get('section', '未知')}\")\n",
    "print(f\"信心分數: {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf9fa64-8c13-4dbe-a5a8-cf634199109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題: 一次吃幾顆？\n",
      "答案: 2\n",
      "來源段落: 【適應症】\n",
      "信心分數: 0.0001\n"
     ]
    }
   ],
   "source": [
    "question = \"一次吃幾顆？\"\n",
    "result = ask_arimidex(question)\n",
    "\n",
    "print(f\"問題: {question}\")\n",
    "print(f\"答案: {result['answer']}\")\n",
    "print(f\"來源段落: {result.get('section', '未知')}\")\n",
    "print(f\"信心分數: {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454ea28-054d-4a12-83fb-5e43f233d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
